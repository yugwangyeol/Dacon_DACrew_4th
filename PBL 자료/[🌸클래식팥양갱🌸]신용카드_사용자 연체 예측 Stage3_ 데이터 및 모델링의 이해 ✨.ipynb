{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd2afcc",
   "metadata": {},
   "source": [
    "# Stage 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d698ca24",
   "metadata": {},
   "source": [
    "<img src='https://drive.google.com/uc?export=download&id=1lLvyacJgfzQINpyIoRT0kzLW8Bw4bsJO' width=\"\" height =\"\" /><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ed7e93",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bfdd81",
   "metadata": {},
   "source": [
    "이번 시간도 전반부에는 Data Preprocessing에서 데이터의 분할을 조금 더 배워보겠습니다. \n",
    "\n",
    "저번 시간에 train과 test의 개념에 대해 배웠던 내용 기억하시나요?🤗\n",
    "\n",
    "Train은 단어 뜻 그대로 \"학습\" 하기 위한 데이터입니다. \n",
    "\n",
    "그럼 **전처리된** train과 test를 불러와 확인해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "375c9bf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'gender', 'car', 'reality', 'child_num', 'income_total',\n",
      "       'income_type', 'edu_type', 'family_type', 'house_type', 'DAYS_BIRTH',\n",
      "       'DAYS_EMPLOYED', 'FLAG_MOBIL', 'work_phone', 'phone', 'email',\n",
      "       'family_size', 'begin_month', 'credit'],\n",
      "      dtype='object')\n",
      "Index(['index', 'gender', 'car', 'reality', 'child_num', 'income_total',\n",
      "       'income_type', 'edu_type', 'family_type', 'house_type', 'DAYS_BIRTH',\n",
      "       'DAYS_EMPLOYED', 'FLAG_MOBIL', 'work_phone', 'phone', 'email',\n",
      "       'family_size', 'begin_month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 불러오기 \n",
    "train = pd.read_csv('train_pre.csv')\n",
    "test = pd.read_csv('test_pre.csv')\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "print(train.columns) # train 열 이름 출력 \n",
    "print(test.columns) # test 열 이름 출력 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03cf904",
   "metadata": {},
   "source": [
    "위에서 출력된 결과를 보면, **credit** 이라는 열이 **train**에만 존재함을 알 수 있습니다. \n",
    "\n",
    "credit은 우리가 예측해야 하는 신용카드 대금의 연체정도 입니다. 즉 **\"정답값(y)\"** 이죠.\n",
    "\n",
    "이처럼 <font color=coral>train은 우리가 이미 정답을 알고있는 데이터</font>로 모델을 통해 학습하는데 쓰입니다. \n",
    "\n",
    "test 는 단어뜻 그대로 \"테스트\"하는 데이터로 우리는 정답을 모르고 학습된 모델을 가지고 정답을 예측해야 하는 데이터 입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e286733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답값인 credit열을  y로 분리한다. \n",
    "\n",
    "data = train.drop('credit',axis=1) # 마지막 행 제거 \n",
    "\n",
    "target = train[['credit']] # 'credit'열 추출 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1611bbe8",
   "metadata": {},
   "source": [
    "# 1. 데이터 분할 - validation set 이해하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d07bc48",
   "metadata": {},
   "source": [
    "Train과 Test데이터의 차이에 대해 이해했다면, 이번에는 validation 데이터에 대해 알아보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a591b2",
   "metadata": {},
   "source": [
    "<img src='https://drive.google.com/uc?export=download&id=1HdQPKcXsQw5c23XSCQ16-Fnt-UNghsCF' width=\"\" height =\"\" /><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9c2728",
   "metadata": {},
   "source": [
    "위 그림에서 보면 train 데이터를 다시한번 train과 val 데이터로 나누었죠? \n",
    "\n",
    "이와 같이 우리에게 주어진 <font color=coral>**train 데이터를 다시한번 나누는 것이 validation**</font>입니다. \n",
    "\n",
    "그렇다면 왜 우리는 한번더 데이터를 분할할까요? \n",
    "\n",
    "앞서 test데이터에는 credit 즉, 정답을 알지 못했습니다. \n",
    "\n",
    "만약 우리가 모든 Train데이터를 학습하는데 사용한다면, 우리는 모델의 성능을 평가할 수 없습니다.\n",
    "\n",
    "따라서 정답을 알고있는 train 데이터를 약 7:3 의 비율로 나누어 val 데이터를 만들고 \n",
    "\n",
    "이를 마치 정답을 모르고 있다고 가정하고 **모델의 성능을 검증하는 데이터**로 사용하게 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be183b3f",
   "metadata": {},
   "source": [
    "## 1.1 hold out "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce5087c",
   "metadata": {},
   "source": [
    "홀드아웃은 위에 배운 내용처럼 우리에게 주어진 데이터 셋을 train 과 val 로 나누는 방법입니다. \n",
    "\n",
    "이는 가장 간단한 데이터 분할 방식으로 실제 모델 선택을 할때는 train 데이터를 train set, val set, test set 세 개의 부분으로 나누는 방식을 많이 사용합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca7b571",
   "metadata": {},
   "source": [
    "<img src='https://drive.google.com/uc?export=download&id=1AS4Uv559gLwLI6cQy3c7kTkOJp1XT81D' width=\"\" height =\"\" /><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050039cb",
   "metadata": {},
   "source": [
    "> - train set : 여러가지 모델을 학습시키는데 사용됩니다. \n",
    "> - val set : 학습한 모델의 성능을 검증해 모델을 선택하는데 사용합니다. \n",
    "> - test set : 훈련과 검증의 과정에서 만나지 못한 데이터이기 때문에 새로운 데이터에 대한 일반화 능력을 덜 편향되게 추정할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ea1c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 간단한 hold out 사용하기 \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "# x,y 로 분리한 train 데이터를 train, val 데이터로 분할 \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(data,target,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a01d0f4",
   "metadata": {},
   "source": [
    "### Inst.\n",
    "- X,y 로 분리된 Train 데이터를 train_set,val_set 으로 분리해보세요 \n",
    "- test_size = 0.3 으로 고정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30e56a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 모듈을 불러오세요 \n",
    "\n",
    "\n",
    "# 먼저 X,y 로 분리된 train데이터를 X_train과 X_val로 한번 분할하세요 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8ac8f",
   "metadata": {},
   "source": [
    "### Hint. \n",
    "-변수명은 첫번째 분할시, X_train,X_valid,y_train,y_valid 를 사용하세요. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c4f81a",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dc7e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 모듈을 불러오세요 \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "# 먼저 X,y 로 분리된 train데이터를 train과 test로 한번 분할하세요 \n",
    "X_train,X_valid,y_train,y_valid = train_test_split(data,target,test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f01184",
   "metadata": {},
   "source": [
    "## 1.2 cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b3a297",
   "metadata": {},
   "source": [
    "보통은 train으로 모델을 훈련하고 validation으로 모델을 검증하는데  \n",
    "여기에는 한 가지 약점이 존재합니다.   \n",
    "고정된 val set을 통해 모델의 성능을 검증하고 수정하는 과정을 반복하면, 결국 내가 만든 모델이 val set에만 잘 동작하는 모델이 되기 때문입니다.   \n",
    "이를 <font color=coral>**val set에 과적합(overfitting)되었다고 하며, 다른 실제 데이터를 가져와 예측을 수행하면 엉망인 결과가 나오게 됩니다.**</font>   \n",
    "\n",
    "이를 해결하고자 나온 방법이 바로 **교차검증(cross validation)** 입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7de8c8",
   "metadata": {},
   "source": [
    "교차검증은 train set의 모든 데이터를 val set으로 교차해 사용하여 모델을 검증하는 방식입니다.   \n",
    "이는 모든 데이터셋을 훈련과 평가에 사용할 수 있다는 장점이 있습니다.   \n",
    "하지만 반복횟수가 많기 때문에 훈련/평가 시간이 오래 걸린다는 단점 역시 존재합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7735ec",
   "metadata": {},
   "source": [
    "### 1.2.1 K-Fold Cross Validation (K-겹 교차 검증)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac15053",
   "metadata": {},
   "source": [
    " <img src='https://drive.google.com/uc?export=download&id=1z9rT7PH5zY-Pcqtn_nyKNPxVptZTaoxK' width=\"\" height =\"\" /><br>  \n",
    "<p style='text-align: right;'> 출처: 우노의 블로그 </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690ddc0d",
   "metadata": {},
   "source": [
    "K-Fold는 가장 일반적으로 사용되는 교차 검증 방법입니다. \n",
    "자세한 k-fold 교차검증 과정은 다음과 같습니다. 위의 그림을 참고하여 학습해주세요! 😊  \n",
    "> 1. 전체 데이터셋을 train과 test로 나눈다. \n",
    "> 2. train set을 train + validation으로 사용하기 위해 k개의 fold로 나눈다.\n",
    "> 3. 첫 번째 fold를 validation으로 사용하고 나머지는 train으로 사용한다. \n",
    "> 4. 모델을 학습한 뒤, 첫번쨰 validation으로 모델을 평가한다. \n",
    "> 5. 차례대로 다음 폴드를 validation set으로 사용한다. \n",
    "> 6. 3~5를 반복하며 총 k개의 성능 결과가 나오며, 이 k개의 평균을 모델 성능으로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbab816b",
   "metadata": {},
   "source": [
    "**sklearn에서 교차검증을 위해 cross_val_score함수를 제공합니다.**  \n",
    "> `cross_val_score(모델,데이터(X),정답값(Y),CV=나눌횟수)`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e777d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv 함수 불러오기 \n",
    "from sklearn.model_selection import cross_val_score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066259ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96654016",
   "metadata": {},
   "source": [
    "# 2. 머신러닝의 모델분류 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12d76a5",
   "metadata": {},
   "source": [
    "<img src='https://drive.google.com/uc?export=download&id=1B-A9DfHJ2773TfzJUGr1DJ22ouYQ61Gu' width=\"\" height =\"\" /><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a1a11",
   "metadata": {},
   "source": [
    "데이터를 예쁘게 나누어 놓았으니 이제는 모델에 데이터를 넣어보아야 합니다. \n",
    "\n",
    "그 전에! 어떤 머신러닝에는 어떤 모델이 있고, 우리가 사용할 수 있는 모델의 종류는 무엇인지 먼저 알아보아야 겠죠? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ed5495",
   "metadata": {},
   "source": [
    "<img src='https://drive.google.com/uc?export=download&id=1V-sO0iDOQ6qR47o9HN8f54a0rG0SGXOX' width=\"\" height =\"\" /><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb8c199",
   "metadata": {},
   "source": [
    "머신러닝의 문제는 크게 정답이 존재하는 지도학습과 정답이 존재하지 않는 비지도학습으로 나누어집니다. \n",
    "\n",
    "**우리가 풀고자 하는 문제는 credit이라는 정답이 있으니 지도학습이겠죠?**\n",
    "\n",
    "지도학습은 또다시 분류와 회귀문제로 나누어지는데, 우리가 해결하고자 하는 프로젝트는 **신용카드의 연체정도를 0,1,2로 분류하는 \"분류\"문제입니다.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5e603",
   "metadata": {},
   "source": [
    "## 2.1 분류(Classification ) 모델 종류 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfca024",
   "metadata": {},
   "source": [
    "### (1) Decision Tree (의사결정 트리) \n",
    "\n",
    ": 의사결정트리는 일련의 분류 규칙을 통해 데이터를 분류,회귀하는 지도학습 모델 중 하나입니다. \n",
    "\n",
    "모델이 tree구조를 가지고 있기 때문에 Decision Tree라는 이름을 가집니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc1412e",
   "metadata": {},
   "source": [
    "<img src='https://drive.google.com/uc?export=download&id=1MVOeU4NE__95owzQjLGJ3jk7GrzHrw1b' width=\"\" height =\"\" /><br>\n",
    "<p style='text-align: right;'> 출처: 우노의 블로그 </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7092eeb3",
   "metadata": {},
   "source": [
    "위 그림은 대표적인 의사결정트리의 예시로, 타이타닉호 탑승객의 생존여부를 나타내고 있습니다. \n",
    "\n",
    "이렇게 특정 기준(질문)에 따라 데이터를 구분하게 되고, 한번의 분기 때마다 변수 영역을 두 개로 구분합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d117b7",
   "metadata": {},
   "source": [
    "결정트리에서 질문이나 정답은 노드(Node)라고 불립니다 \n",
    "1. 맨 처음 분류 기준을 **Root Node**\n",
    "2. 중간 분류 기준을 **Intermediate Node** \n",
    "3. 맨 마지막 노드를 **Terminal Node 혹은 Leaf Node** 라고 합니다. \n",
    "\n",
    "결정 트리의 기본 아이디어는 leaf node가 가장 섞이지 않은 상태로 완전히 분류되는 것, 즉 복잡성이 낮도록 만드는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e30a2c",
   "metadata": {},
   "source": [
    "### (2) KNN (k-nearnest neighbor) \n",
    ": KNN은 K-최근접 이웃법으로 분류문제에 사용되는 알고리즘 입니다. \n",
    "\n",
    "새로운 데이터가 들어왔을 때, 해당 데이터와 가장 가까이에 있는 k개의 데이터를 확인해, 새로운 데이터의 특성을 파악하는 방법입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aaf61a",
   "metadata": {},
   "source": [
    "<img src='https://drive.google.com/uc?export=download&id=1MjpKgJBDvE-t91ktraz870O-uGgZL11U' width=\"\" height =\"\" /><br>\n",
    "<p style='text-align: right;'> 출처: Gom Guard의 라이브러리 </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eec468",
   "metadata": {},
   "source": [
    "위의 그림의 물음표에는 세모와 동그라미 중, 어떤 모양이 들어갈까요? \n",
    "\n",
    "**최근접 이웃 알고리즘**은 \"?\"의 주변에 있는 것이 동그라미이기 때문에 \"?\"를 동그라미라고 판단하는 알고리즘입니다. \n",
    "\n",
    "매우 간단하고 직관적이죠? 🤗 \n",
    "\n",
    "그렇지만, 단순히 가까이 있다고 같게 여기는 것은 부적절하다고 느껴집니다. \n",
    "\n",
    "따라서, 단순히 '주변에 가장 가까이 있는게 무엇인가?'가 아닌 **'주변에 가장 가깝고 많이 있는 것이 무엇인가?'** 라는 방식을 사용합니다. \n",
    "이방식을 <font color=coral>**'k-최근접 이웃 알고리즘'**</font>이라고 부르며, k는 가장 가까이에 있는 데이터의 개수를 의미합니다.\n",
    "- 즉, k가 1일 때는 '?'를 파란 동그라미라고 판단하지만, k가 4일때는 '?'를 빨간 세모라고 판단합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed961ae",
   "metadata": {},
   "source": [
    "**더 많은 분류모델은 다음 stage에서 자세히 다룰 예정입니다. 😁**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220aea0d",
   "metadata": {},
   "source": [
    "# 3. 모델링 기초 \n",
    "\n",
    "그렇다면 이번에는 간단한 분류모델 중 하나인 decisionTree 를 사용한 예측을 진행해 보겠습니다. \n",
    "\n",
    "모델을 통해 예측값을 도출하는 과정은 매우 간단합니다. \n",
    "> **데이터를 준비하고 > 모델에 데이터를 넣고 > 예측한다 > 평가한다**\n",
    "\n",
    "같이 한번 해볼까요? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56d5023",
   "metadata": {},
   "source": [
    "이번 실습에서 예시는 우리에게 주어진 데이터가 아닌 sklearn 내장 데이터인 iris로 해보겠습니다.   \n",
    "여기서 우리는 hold-out 방식과 cross_validation방식 두가지를 모두 사용해보겠습니다.\n",
    "\n",
    "어렵지 않으니 잘 따라해보세요! 😆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ca51940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 \n",
    "from sklearn import datasets \n",
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data[:,[2,3]]\n",
    "iris_y = iris.target\n",
    "\n",
    "# 주어진 데이터를 train 과 val로 분리합니다. \n",
    "iris_train, iris_val, iris_y_train, iris_y_val = train_test_split(iris_X,iris_y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20272f2",
   "metadata": {},
   "source": [
    "hold out을 사용한 데이터 준비가 완료되었습니다. 이제 결정트리 모델을 불러와 보겠습니다. \n",
    "\n",
    "이때, **모델을 import로 불러온 뒤, 반드시 변수에 할당해 주셔야 합니다.**\n",
    "\n",
    "밑에서 같이 해볼까요? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d37487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결정트리 모델 불러오기 \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# 변수에 할당 \n",
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a09b8b",
   "metadata": {},
   "source": [
    "이제 모든 준비가 끝났습니다. \n",
    "\n",
    "모델에 학습할 데이터를 넣고 학습시킬 때는 <font color=green>**model.fit()**</font> 함수를 사용합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "358c4c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습할 데이터를 넣는다. \n",
    "dt = dt.fit(iris_train,iris_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab6e21b",
   "metadata": {},
   "source": [
    "모델의 predict역시 <font color=green>**model.predict()**</font> 로 간단하게 할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4834eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val 데이터로 학습된 모델을 테스트 한다. \n",
    "pred = dt.predict(iris_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413f92cc",
   "metadata": {},
   "source": [
    "여기서는 가장 직관적으로 이해하기 쉬운 정확도를 평가지표로 사용하겠습니다. \n",
    "\n",
    "(평가지표의 대한 내용은 다음 단원에서 배우니 걱정마세요! 😁)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9a3babe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# 얼마나 잘 예측했는지 테스트 해본다. \n",
    "from sklearn.metrics import accuracy_score\n",
    "pred_acc = accuracy_score(iris_y_val,pred)\n",
    "print(pred_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8977aa52",
   "metadata": {},
   "source": [
    "이번에는 앞서 배운 cross validation(교차검증)을 활용해 예측해보겠습니다. \n",
    "cross_val_score은 교차검증한 만큼 리스트로 결과값을 내보냅니다.   \n",
    "이를 np.mean()을 통해 평균한 값을 우리는 성능으로 사용합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "747be139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9532\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "scores = cross_val_score(dt,iris_X,iris_y,cv=4)\n",
    "print(np.round(np.mean(scores),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab38dfe",
   "metadata": {},
   "source": [
    "### Inst. \n",
    "- X,y 데이터를 cross_validation과 decisiontree를 활용해 성능을 출력해보세요.\n",
    "\n",
    "- cross_val_score 함수의 결과값을 평균하여 성능을 측정하세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d06729ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train.drop('credit',axis=1) # 마지막 행 제거 \n",
    "\n",
    "target = train[['credit']] # 'credit'열 추출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "392f9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결정트리 모델 불러오기 \n",
    "\n",
    "\n",
    "\n",
    "# 모델 변수에 할당하기 \n",
    "\n",
    "\n",
    "\n",
    "# cross_val_score를 통해 학습하고 성능 내보내기 \n",
    "\n",
    "\n",
    "\n",
    "# 평균 성능 구하기 -> np.mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ad1c23",
   "metadata": {},
   "source": [
    "### Hint. \n",
    "- np.mean()을 사용하기 위해서는 `import numpy as np`를 불러와야 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cb9b58",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9b25248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4659"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결정트리 모델 불러오기 \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "\n",
    "# 변수에 할당 \n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# cross_val_score를 통해 학습하고 성능 내보내기 \n",
    "score = cross_val_score(dt,data,target,cv=4)\n",
    "\n",
    "\n",
    "# 평균 성능 구하기 -> np.mean()\n",
    "import numpy as np\n",
    "np.round(np.mean(score),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e833e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb999c71",
   "metadata": {},
   "source": [
    "# 4. 예측값의 평가 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8432eadc",
   "metadata": {},
   "source": [
    "<img src='https://drive.google.com/uc?export=download&id=1Lp4xfhJS--xeXFcThEIm7IJ4nzcQ4XXg' width=\"\" height =\"\" /><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa70e931",
   "metadata": {},
   "source": [
    "앞에서 우리는 모델을 통해 예측값을 도출했습니다. \n",
    "\n",
    "우리가 도출한 예측값이 얼마나 정확한지 평가하는 일만 남았습니다. 👍\n",
    "\n",
    "이 대회에서는 logloss를 사용하여 평가하도록 명시되어있지만, 분류의 평가지표는 더 다양합니다.\n",
    "\n",
    "이번 단원에서는 분류의 또다른 성능지표 **confusion matrix를** 먼저 배워보도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4841a8",
   "metadata": {},
   "source": [
    "## 4.1 Confusion Matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef29867e",
   "metadata": {},
   "source": [
    "혼동행렬 이라 불리는 confusion matrix는 분류모델의 성능을 평가하는 지표입니다. \n",
    "\n",
    "'분류 모델이 예측한 값' 과 정답값인 '원래의 값'간의 관계를 표로 나타내어 \n",
    "\n",
    "이를 통해 정확도(accuracy), 정밀도(precision), 민감도(sensitivity), f1 score등을 파악할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed711dc",
   "metadata": {},
   "source": [
    "<img src='https://drive.google.com/uc?export=download&id=1bgj16Fb4k5fo3VLPfEYoqfUrVI-8jRTp' width=\"\" height =\"\" /><br>\n",
    "<p style='text-align: right;'> 출처: 울창한 데이터 숲 </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e4cf37",
   "metadata": {},
   "source": [
    "혼동행렬은 위와 같이 총 4가지의 경우의 수를 가집니다. \n",
    "**\"혼동\"**  행렬인 만큼 매우 헷갈리니 **\"두개의 알파벳\"** 만 잘 기억해보도록 합시다.😉\n",
    "-  **첫번째 알파벳**    \n",
    "   : 예측값과 실제값이 동일한지 여부를 나타냅니다. 동일한 경우는 'T'(True) 상이한 경우 'F'(False)로 적습니다. \n",
    "\n",
    "-  **두번째 알파벳**   \n",
    "    : 모델이 예측한 값을 나타냅니다. 모델이 맞다고 예측하면 'P'(Positive), 틀리다고 예측하면 'N'(Negative)로 적습니다.\n",
    "\n",
    "혼동행렬은 파이썬에서 `sklearn.metrics`를 통해 구할 수 있습니다. 한번 불러와 볼까요? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbdaeb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  0,  0],\n",
       "       [ 0, 12,  1],\n",
       "       [ 0,  0, 16]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(iris_y_val,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7018fd98",
   "metadata": {},
   "source": [
    "*위 결과에서 보이듯이 우리가 해결하고 있는 프로젝트는 다중분류문제 입니다.*  \n",
    "*하지만 우리는 조금 쉬운 이해를 위해 **이진분류를 기준**으로 배워보겠습니다.*  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393bbee2",
   "metadata": {},
   "source": [
    "(1) 정확도(accuracy) : (TP+TN) / (TP+TN+FN+FP)  \n",
    "    \n",
    "정확도란, 전체 중 모델이 바르게 분류한 비율을 뜻합니다.   \n",
    "앞에서도 해봤지만, 정확도는 `accuracy_score()`를 통해 구해볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986eb2dc",
   "metadata": {},
   "source": [
    "(2) 정밀도 (precision) : TP / (TP+FP)  \n",
    "\n",
    "정밀도는 모델이 P로 분류한 것 중 실제값이 P인 비율을 뜻합니다.   \n",
    "(정밀도는 `precision_score()`을 통해 구할 수 있습니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d23a19",
   "metadata": {},
   "source": [
    "(3) 재현도 (recall)  : TP / (TP+FN)  \n",
    "\n",
    "재현도란 실제값이 P인 것 중 모델이 P라 분류한 비율을 뜻합니다.   \n",
    "(재현도는 `recall_score`를 통해 구할 수 있습니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2460d3",
   "metadata": {},
   "source": [
    "(4) F1 score \n",
    "\n",
    "F1 score은 Precision과 Recall의 조화평균을 뜻합니다. \n",
    "\n",
    "* 왜 F1 score을 사용할까요? \n",
    "\n",
    ">분류문제에서 정확도 대신 F1 score을 쓰는 경우는 데이터가 불균형 할 떄 입니다.  \n",
    ">데이터가 불균형 할 때는 정확도보다 F1 score를 사용하는 것이 좀 더 일반화된 성능을 얻을 수 있습니다.  \n",
    "  \n",
    "(F1 score은 `f1_score`를 통해 구할 수 있습니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5bf3c7",
   "metadata": {},
   "source": [
    "**정확도를 제외한 정밀도, 재현도 , f1 score은 `sklearn.metrics.classification_report`를 통해 구할 수도 있습니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd773ec",
   "metadata": {},
   "source": [
    "### Inst.\n",
    "- 앞서 실습에 사용된 iris 데이터의 정확도, 정밀도, 재현도, f1_score을 구해보세요.\n",
    "- 정밀도, 재현도,fl_score은 한번에 구해보세요! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79ad6f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 \n",
    "\n",
    "\n",
    "\n",
    "# 정밀도 , 재현도 , f1_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f1974b",
   "metadata": {},
   "source": [
    "### Hint. \n",
    "- 정밀도, 재현도, f1_score을 한번에 구하려면... sklearn.metrics.classification_report를 이용해야합니다. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3929d795",
   "metadata": {},
   "source": [
    "### Solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "296d6a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.9777777777777777\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.94      1.00      0.97        16\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 정확도 \n",
    "from sklearn.metrics import accuracy_score \n",
    "print('정확도: ',accuracy_score(iris_y_val,pred))\n",
    "print()\n",
    "\n",
    "# 정밀도 \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(iris_y_val,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba75f1",
   "metadata": {},
   "source": [
    "## 4.2  Logloss 란? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ae31a4",
   "metadata": {},
   "source": [
    "### 4.2.1 loss 란 무엇인가? \n",
    "loss 는 지도학습시 모델이 예측한 값과 실제 정답의 차이(거리 또는 오차)입니다.   \n",
    "즉, 우리는 이 loss 값이 작을 수록 모델이 정확한 예측을 한 것이라고 할 수 있습니다.  \n",
    "  \n",
    "이 대회에서는 평가지표로 logloss를 사용하라고 명시되어 있습니다.   \n",
    "logloss는 이름에서 알 수 있듯이 log를 사용하여 모델을 평가합니다.  \n",
    "특이한 점은 음의 로그함수를 사용한다는 점인데요  \n",
    "아래 그래프를 살펴볼까요? 😊\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db654d7",
   "metadata": {},
   "source": [
    "<img src='https://drive.google.com/uc?export=download&id=1b-aIJU5j1N-CgIHB3w2tTTQvIrNafyN6' width=\"\" height =\"\" /><br>\n",
    "<p style='text-align: right;'> 출처: Hwi's ML doc </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98970900",
   "metadata": {},
   "source": [
    "logloss에서 사용하는 그래프는 빨간색 그래프인 -log(x) 형태입니다.   \n",
    "어떤 모델이 분류한 예측값의 확률이 100%라면 -log(1) 인 값을 logloss값으로 반환합니다.   \n",
    "  \n",
    "만약 확률이 20%라면 -log(0.2) 인 값을 logloss로 반환합니다.   \n",
    "즉, 확률이 낮을 수록 logloss값이 기하급수적으로 증가하게 되는 것입니다.   \n",
    "  \n",
    "**logloss 값은 분류모델 평가지표로 사용하는 지표 중 하나이며, 0에 가까울수록 정확하다는 뜻이고, 확률이 낮아질수록 logloss값은 급격하게 커집니다.** \n",
    "\n",
    "그렇다면 이제 logloss를 사용해 모델을 평가하고 submission file을 출력해볼까요? 😊"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a677c8c7",
   "metadata": {},
   "source": [
    "*logloss는 확률을 통해 모델을 평가합니다.*  \n",
    "*따라서 모델의 predict_proba()를 통해 예측값을 구한 후 logloss값을 측정해야 합니다!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3e49cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f8d3879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.73855792280441\n"
     ]
    }
   ],
   "source": [
    "# 모델을 학습시키세요 \n",
    "dt = dt.fit(X_train,y_train)\n",
    "\n",
    "# X_val의 확률 예측값을 구하세요 \n",
    "y_pred = dt.predict_proba(X_valid)\n",
    "\n",
    "# logloss값을 구하세요. \n",
    "print(log_loss(y_valid['credit'],y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d588a8c6",
   "metadata": {},
   "source": [
    "### submission 제출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25bdc0a",
   "metadata": {},
   "source": [
    "### Inst."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec176ad",
   "metadata": {},
   "source": [
    "- test 데이터를 가지고 최종 예측값을 구하고 'first_submission_dt.csv' 파일을 내보내세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69823bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터를 가지고 최종 예측값을 구합니다. \n",
    "\n",
    "\n",
    "# submission 파일을 만듭니다. \n",
    "\n",
    "\n",
    "# submission 파일을 내보냅니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43a633b",
   "metadata": {},
   "source": [
    "### Hint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea50c72f",
   "metadata": {},
   "source": [
    "- 예측값은 predict_proba를 통해 구합니다. \n",
    "- 내보내기는 stage1을 참고하세요! 😊"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da40abdb",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ea689d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터를 가지고 최종 예측값을 구한다. \n",
    "y_pred = dt.predict_proba(test)\n",
    "\n",
    "\n",
    "# submission 파일을 만듭니다.\n",
    "submission.loc[:,1:] = y_pred\n",
    "\n",
    "\n",
    "# submission 파일을 내보냅니다. \n",
    "submission.to_csv('first_submission_dt.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90059c5",
   "metadata": {},
   "source": [
    "### Inst. \n",
    "- cross validation을 사용한 submission 제출 코드를 이해해보세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef4edc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답값인 credit열을  y로 분리한다. \n",
    "\n",
    "data = train.drop('credit',axis=1) # 마지막 행 제거 \n",
    "\n",
    "target = train[['credit']] # 'credit'열 추출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08b150d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0 : logloss:16.590621616754152\n",
      "FOLD 1 : logloss:16.675467439341798\n",
      "FOLD 2 : logloss:16.743897458504236\n",
      "FOLD 3 : logloss:17.115984068693216\n",
      "FOLD 4 : logloss:17.129039739226165\n",
      "Mean:16.85100206450391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "def run_kfold(clf):\n",
    "    folds=StratifiedKFold(n_splits=5, shuffle=True, random_state=55)\n",
    "    outcomes=[]\n",
    "    sub=np.zeros((test.shape[0], 3))  \n",
    "    for n_fold, (train_index, val_index) in enumerate(folds.split(data, target)):\n",
    "        X_train, X_val = data.iloc[train_index], data.iloc[val_index]\n",
    "        y_train, y_val = target.iloc[train_index], target.iloc[val_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        predictions=clf.predict_proba(X_val)\n",
    "        \n",
    "        logloss=log_loss(y_val['credit'], predictions)\n",
    "        outcomes.append(logloss)\n",
    "        print(f\"FOLD {n_fold} : logloss:{logloss}\")\n",
    "        \n",
    "        sub+=clf.predict_proba(test)\n",
    "        \n",
    "        \n",
    "    mean_outcome=np.mean(outcomes)\n",
    "    \n",
    "    print(\"Mean:{}\".format(mean_outcome))\n",
    "    return sub/folds.n_splits\n",
    "\n",
    "my_submission = run_kfold(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1535302f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26458</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26459</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26460</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>36452</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>36453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>36454</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>36455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>36456</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index    0    1    2\n",
       "0     26457  0.0  0.2  0.8\n",
       "1     26458  0.4  0.0  0.6\n",
       "2     26459  0.2  0.4  0.4\n",
       "3     26460  0.2  0.4  0.4\n",
       "4     26461  0.0  0.6  0.4\n",
       "...     ...  ...  ...  ...\n",
       "9995  36452  0.2  0.6  0.2\n",
       "9996  36453  0.0  0.4  0.6\n",
       "9997  36454  0.2  0.0  0.8\n",
       "9998  36455  0.0  0.6  0.4\n",
       "9999  36456  0.4  0.2  0.4\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.loc[:,1:]=my_submission\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621b6f5b",
   "metadata": {},
   "source": [
    "### Hint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ddfb30",
   "metadata": {},
   "source": [
    "- empty "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4617f3",
   "metadata": {},
   "source": [
    "### Solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6996d3",
   "metadata": {},
   "source": [
    "- empty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ee11c3",
   "metadata": {},
   "source": [
    "# Outro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dfd7f5",
   "metadata": {},
   "source": [
    "데이터의 분할과 모델링을 직접 경험해보니 어떠신가요?   \n",
    "별거 없죠? 😏  \n",
    "\n",
    "조금 더 심화되는 내용들은 구글링을 통해 참고해서 학습해주세요!   \n",
    "\n",
    "마지막 cross validation을 사용한 submission 제출 부분은 반드시 직접 코드를 따라치면서 이해해보세요.   \n",
    "실력향상에 많은 도움이 될겁니다 :)  \n",
    "\n",
    "아직은 평가지표의 결과가 그렇게 높지 않지만, 다음 stage부터 성능을 높이는 여러 방법에 대해 배우게 될 예정입니다.  \n",
    "**오늘도 수고하셨습니다. 다음 stage에서 만나요 ✌️**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
